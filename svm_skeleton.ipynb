{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angelgold1004/stock_market_analysis/blob/main/svm_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM(Suport Vector Machine)\n",
        "\n",
        "\n",
        "**[참고자료]** \n",
        "- [SVM 개념](https://www.notion.so/SVM-88a8db59158d4886b244d523c7214f19)\n",
        "- [sklearn - SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
        "- [sklearn - SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html?)"
      ],
      "metadata": {
        "id": "imT3Z5yUJ9lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [실습 01] Binary classification"
      ],
      "metadata": {
        "id": "3IyHdA0IOB8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습 목표\n",
        "---\n",
        "- 주어진 데이터를 예측하기 위해서 어떠한 AI 기술을 활용해야하는지 이해합니다.\n",
        "- 의사결정트리 및 SVM 모델을 이해합니다."
      ],
      "metadata": {
        "id": "UHhc5UFvOGLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습 목차\n",
        "---\n",
        "\n",
        "1. **데이터 읽기:** 주어진 데이터('Dataset.csv')를 불러오고 Dataframe 구조를 확인\n",
        "\n",
        "2. **데이터 전처리:** 머신러닝 모델에 필요한 입력값 형식으로 데이터 처리\n",
        "\n",
        "3. **머신러닝 모델 학습:** 분류 모델을 사용하여 학습 수행, 평가 및 예측 수행\n",
        "\n",
        "3. **머신러닝 모델 성능 개선:** 생성한 모델의 하이퍼파라미터를 튜닝하여 모델 성능을 개선"
      ],
      "metadata": {
        "id": "1BQ_OljEPC-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습 개요\n",
        "---\n",
        "머신러닝 프로세스 과정을 이해하고, 데이터 전처리, 학습, 평가 단계를 구현합니다."
      ],
      "metadata": {
        "id": "Ocp7oKQUPFta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 데이터 읽기\n",
        "---\n",
        "\n",
        "### 1.1 라이브러리 불러오기\n",
        "---\n",
        "머신러닝에 필요한 주요 라이브러리를 불러옵니다.\n",
        "\n",
        " - **numpy**: 수치형 데이터를 배열 구조로 처리하기 위한 라이브러리\n",
        " - **pandas**: 데이터프레임을 다루기 위한 라이브러리\n",
        " - **matplotlib.pyplot**: 데이터시각화를 위한 라이브러리\n",
        " - **seaborn**: 데이터시각화를 위한 라이브러리"
      ],
      "metadata": {
        "id": "B0ApTH_ZPaOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "Zl_2ot5-OApi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 데이터 불러오기\n",
        "---\n",
        "pandas를 사용하여 dataframe 형태로 데이터를 불러옵니다. 데이터프레임을 담을 변수는 `df`로 설정합니다."
      ],
      "metadata": {
        "id": "f4C6vS2IPdA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset.csv 파일을 읽어오기\n",
        "df = pd.___________(___________)\n",
        "\n",
        "# 데이터프레임의 상위 5개 항목 출력\n",
        "df.___________"
      ],
      "metadata": {
        "id": "5EW716aKN_R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7개의 컬럼을 갖는 데이터프레임을 불러왔습니다."
      ],
      "metadata": {
        "id": "igB83KgURX6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1.3 데이터 탐색\n",
        "---\n",
        "\n",
        "`df`의 컬럼별 요약정보(info)를 확인합니다. 각 컬럼별 데이터 타입과 결측치 여부를 확인합니다."
      ],
      "metadata": {
        "id": "Qpyq2NnGRaov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 컬럼별 요약정보\n",
        "df.___________"
      ],
      "metadata": {
        "id": "8CU5zAliRdVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 데이터 전처리\n",
        "----\n",
        "머신러닝을 하기 위한 데이터 전처리를 수행합니다. 독립변수(X)와 종속변수(Y)로 각 컬럼을 나누고, 학습용 데이터와 테스트용 데이터로 분할하는 데이터 분할을 수행합니다. 독립변수(X)에 대해서 정규화를 수행합니다."
      ],
      "metadata": {
        "id": "MnbDL8AmRfwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 종속변수, 독립변수 할당\n",
        "-----"
      ],
      "metadata": {
        "id": "fXDeqINnRz9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 컬럼에서 0~5번 컬럼에 해당하는 값을 독립변수(X)로 할당\n",
        "X = ________________\n",
        "\n",
        "# nano_parcticle 컬럼을 종속변수(y)로 할당\n",
        "y = ________________\n",
        "\n",
        "# X에 할당된 값 확인\n",
        "X.head()"
      ],
      "metadata": {
        "id": "sZV7RbbpR2jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X에 `target`를 제외한 모든 컬럼이 할당되었습니다."
      ],
      "metadata": {
        "id": "zltlKroSSAPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 정규화(스케일링)\n",
        "-----\n",
        "컬럼별 데이터 크기 및 분포의 차이가 있으므로 StandardScaler를 사용하여 정규화를 수행하겠습니다.\n"
      ],
      "metadata": {
        "id": "qn0Ry7QnR84l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn에서 제공하는 StandardScaler를 임포트\n",
        "from sklearn.preprocessing import _____________\n",
        "\n",
        "# StandardScaler() 객체 선언\n",
        "sc = _____________\n",
        "\n",
        "# X를 StandardScaler를 사용하여 z-점수 정규화(StandardScaler)수행\n",
        "X = sc._____________(_________)\n",
        "\n",
        "# 변환된 결과 출력\n",
        "print(X)"
      ],
      "metadata": {
        "id": "0KPI-5A0SGuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(X[0])):\n",
        "    print('{} 컬럼의 평균: {:.2f}, 표준편차:{}'.format(i, X[:, i].mean(), X[:, i].std()))"
      ],
      "metadata": {
        "id": "RsAqHBU9e69i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터의 범위가 평균 0, 표준편차 1을 기준으로 변경되었습니다."
      ],
      "metadata": {
        "id": "ZwQ6oKbmSEvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 학습용, 테스트용 데이터 분할\n",
        "-----\n",
        "train_test_split()을 사용하여 전처리가 완료된 데이터를 분할합니다."
      ],
      "metadata": {
        "id": "yJR49JtbSL8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn에서 제공하는 train_test_split 임포트\n",
        "from sklearn.model_selection import _____________\n",
        "\n",
        "# 데이터 분할\n",
        "# - 테스트용 데이터의 비율을 20%로 설정\n",
        "# - 동일한 샘플링 결과를 얻기 위해 random_state 설정\n",
        "# - y의 비율을 기준으로 샘플링\n",
        "X_train, X_test, y_train, y_test = _____________(___,  ___,test_size = 0.2, random_state = 42, _____________)\n",
        "\n",
        "# 분할된 변수의 결과 출력\n",
        "print('X: {}, X_train: {}, X_test:{}'.format(X.shape, X_train.shape, X_test.shape))\n",
        "print('y: {}, y_train: {}, y_test:{}'.format(y.shape, y_train.shape, y_test.shape))"
      ],
      "metadata": {
        "id": "h3hzN30MSQ7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1000개의 데이터가 학습용 데이터 700개, 테스트용 데이터 300개로 분할되었습니다."
      ],
      "metadata": {
        "id": "-rVyvcqhSUvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y값을 기준으로 계층적(stratified) 샘플링이 적용되어 데이터가 분할되었는지 여부를 확인\n",
        "print(y.value_counts()/len(y) * 100)\n",
        "print(y_train.value_counts()/len(y_train) * 100)\n",
        "print(y_test.value_counts()/len(y_test) * 100)"
      ],
      "metadata": {
        "id": "jQsRCmhkSfU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0과 1의 비율이 학습용 데이터셋과 테스트용 데이터 셋 모두 약 59:41로 기존 데이터의 비율과 동일하게 분할되었습니다."
      ],
      "metadata": {
        "id": "1VjJLVgBSkfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 머신러닝 모델 수행\n",
        "-----\n",
        "\n",
        "다음의 알고리즘을 사용하여 분류(classifier) 모델을 생성하는 머신러닝 학습을 수행합니다.\n",
        "\n",
        "- 의사결정나무\n",
        "- 서포트벡터머신"
      ],
      "metadata": {
        "id": "7XwzBwwsSpG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 의사결정나무(DecisionTree)\n",
        "---\n"
      ],
      "metadata": {
        "id": "eRgXsA9jSvSO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 3.1.1 학습\n",
        "\n",
        "DecisionTreeClassifier 클래스의 기본 매개변수를 사용하여 모델을 학습시킵니다."
      ],
      "metadata": {
        "id": "a3dq3e2NXm4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DecisionTreeClassifier 라이브러리 불러오기\n",
        "from sklearn.tree import _______________________\n",
        "\n",
        "# 기본 매개변수를 사용하는 DecisionTreeClassifier 생성\n",
        "tree = _______________________(random_state=42)\n",
        "\n",
        "# 생성한 tree 객체를 학습용 데이터를 사용하여 학습\n",
        "tree.__________(___________,  ___________)"
      ],
      "metadata": {
        "id": "ZIM24brCSl7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1.2 학습결과 시각화\n",
        "-----"
      ],
      "metadata": {
        "id": "lHCU9YGUS4VJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "tree_img = export_graphviz(tree,feature_names=df.columns[:len(df.columns)-1],\n",
        "                      class_names=[\"1\",\"0\"])\n",
        "graphviz.Source(tree_img)"
      ],
      "metadata": {
        "id": "7Iz76Fm5S9PN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1.3 평가"
      ],
      "metadata": {
        "id": "g9LZxj_XS7cX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습용 데이터 셋의 정확도\n",
        "print(\"train 세트 정확도: {:.3f}\".format(tree.___________(___________,  ___________)))\n",
        "\n",
        "# 테스트용 데이터 셋의 정확도\n",
        "print(\"test 세트 정확도: {:.3f}\".format(tree.___________(___________,  ___________)))"
      ],
      "metadata": {
        "id": "wywqeZtETUBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본 매개변수를 사용하여 학습시킨 모델의 테스트 정확도는 약 86.3%입니다."
      ],
      "metadata": {
        "id": "zCR8AuW_TV9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1.4 예측\n",
        "-----"
      ],
      "metadata": {
        "id": "Cd3pkulFTaXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_test를 입력으로하여 결과값 예측\n",
        "y_pred = tree.predict(X_test)\n",
        "print('예측값:' , y_pred)\n",
        "print('실제값:' , y_test.values)"
      ],
      "metadata": {
        "id": "RXLGzoF3TeOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "예측값과 실제값의 차이가 존재하는 항목이 보입니다. 차이가 나는 항목에 대해 산점도를 그려 확인해보겠습니다."
      ],
      "metadata": {
        "id": "uCM_dHQPTfp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "plt.scatter(np.arange(len(y_pred)), y_pred - y_test)"
      ],
      "metadata": {
        "id": "g_Us4UtNTjCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제값과 예측값의 차이가 0으로 대부분의 값이 0에 분포합니다. 실제값이 1인데 0으로 예측한 항목은 아래 부분에, 실제값이 0인데 1로 예측한 항목은 그래프 윗부분에 표시되었습니다."
      ],
      "metadata": {
        "id": "nkUBrthCTmzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# 혼동행렬 생성\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# 혼동행렬 시각화\n",
        "cm_display = ConfusionMatrixDisplay(cm).plot()"
      ],
      "metadata": {
        "id": "vHA1J3cYTpAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제값이 0인데 예측을 1로 하는 경우가 22건, 실제값이 1인데 예측을 0으로 하는 경우가 19건이 존재합니다."
      ],
      "metadata": {
        "id": "9vrEmAjLTrkm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 서포트벡터머신(SVM)\n",
        "----------\n"
      ],
      "metadata": {
        "id": "uA2zerOOTzut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 3.2.1 학습\n",
        "-----\n",
        "SVC 클래스의 기본 매개변수를 사용하여 모델을 학습시킵니다."
      ],
      "metadata": {
        "id": "aYogE3qPXtXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVC 라이브러리 불러오기\n",
        "from sklearn.svm import _________\n",
        "\n",
        "# 기본 매개변수를 사용하여 SVC 객체 생성\n",
        "classifier = _________\n",
        "\n",
        "# 생성한 SVC 객체를 학습용 데이터를 사용하여 학습\n",
        "classifier._________(_________, _________)"
      ],
      "metadata": {
        "id": "E5pteGLzT_QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.2 평가\n",
        "-----"
      ],
      "metadata": {
        "id": "jpDUoOp2T-4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습용 데이터 셋의 정확도\n",
        "print(\"train 세트 정확도: {:.3f}\".format(classifier._________(_________, _________)))\n",
        "\n",
        "# 테스트용 데이터 셋의 정확도\n",
        "print(\"test 세트 정확도: {:.3f}\".format(classifier._________(_________, _________)))"
      ],
      "metadata": {
        "id": "XbkKwlB2UDcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본 매개변수를 사용하여 학습시킨 모델의 테스트 정확도는 약 87.7%입니다."
      ],
      "metadata": {
        "id": "Z1SiEBypUFN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1.3 예측\n",
        "-----"
      ],
      "metadata": {
        "id": "RiAjTV1EUI4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# 혼동행렬 생성\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# 혼동행렬 시각화\n",
        "cm_display = ConfusionMatrixDisplay(cm).plot()"
      ],
      "metadata": {
        "id": "WH6fbz9JUKEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제값이 0인데 예측을 1로 하는 경우가 19건, 실제값이 1인데 예측을 0으로 하는 경우가 18건 존재합니다."
      ],
      "metadata": {
        "id": "5QczW7olUS85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 모델 성능 개선\n",
        "-----\n",
        "\n",
        "모델 생성시 주요 매개변수를 변화시켜보고, 그에 따른 정확도 변화를 확인합니다."
      ],
      "metadata": {
        "id": "Y7uwxUztU4Zq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 DecisionTree 매개변수 변경\n",
        "-----"
      ],
      "metadata": {
        "id": "YnOutCOzWA7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1.1 max_depth"
      ],
      "metadata": {
        "id": "9-oE2RoEWOGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  변경할 max_depth \n",
        "max_depth=[1,2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "# 매개변수에 따른 학습데이터 셋, 테스트 데이터셋에 대한 정확도를 저장하기 위한 변수\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for i in max_depth:\n",
        "    # max_depth 변경하여 모델 생성\n",
        "    tuned_tree = DecisionTreeClassifier(random_state=42, ___________ = i)\n",
        "\n",
        "    # 생성한 tree 객체를 학습용 데이터를 사용하여 학습\n",
        "    tuned_tree.fit(X_train, y_train)\n",
        "\n",
        "    # 학습데이터 셋, 테스트 데이터셋에 대한 정확도를 저장\n",
        "    train_scores.append(tuned_tree.score(X_train, y_train))\n",
        "    test_scores.append(tuned_tree.score(X_test, y_test))\n",
        "    \n",
        "    # 정확도 출력\n",
        "    print(\"max_depth = {}, train 세트 정확도: {:.3f}, test 세트 정확도: {:.3f}\".\\\n",
        "          format(i, train_scores[i-1], test_scores[i-1]))"
      ],
      "metadata": {
        "id": "yjZQZBjkWR7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 매개변수 변화에 따른 학습데이터와 테스트데이터에 대한 정확도 변화 시각화\n",
        "plt.title('DecisionTreeClassifier Scores by max_depth')\n",
        "plt.plot(max_depth, train_scores, label='Train',linewidth=2, marker='o')\n",
        "plt.plot(max_depth, test_scores, label='Test',linewidth=2, marker='o')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "gMx8713wWUan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`max_depth`의 값을 크게 설정할 수록 학습용 데이터의 성능은 증가하고 테스트용 데이터의 정확도는 증가하다가 어느 시점부터 감소함을 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "MVAj6TurWWa3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1.2 min_samples_split"
      ],
      "metadata": {
        "id": "mRoGgIruWYJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  변경할 min_samples_split \n",
        "min_samples_split =[2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "# 매개변수에 따른 학습데이터 셋, 테스트 데이터셋에 대한 정확도를 저장하기 위한 변수\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for i in min_samples_split:\n",
        "    # min_samples_split 변경하여 모델 생성\n",
        "    tuned_tree = DecisionTreeClassifier(random_state=42, __________________ = i)\n",
        "\n",
        "    # 생성한 tree 객체를 학습용 데이터를 사용하여 학습\n",
        "    tuned_tree.fit(X_train, y_train)\n",
        "\n",
        "    # 학습데이터 셋, 테스트 데이터셋에 대한 정확도를 저장\n",
        "    train_scores.append(tuned_tree.score(X_train, y_train))\n",
        "    test_scores.append(tuned_tree.score(X_test, y_test))\n",
        "    \n",
        "    # 정확도 출력\n",
        "    print(\"min_samples_split = {}, train 세트 정확도: {:.3f}, test 세트 정확도: {:.3f}\".\\\n",
        "          format(i, train_scores[i-2], test_scores[i-2]))"
      ],
      "metadata": {
        "id": "EsiF5Eh4WX2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 매개변수 변화에 따른 학습데이터와 테스트데이터에 대한 정확도 변화 시각화\n",
        "plt.title('DecisionTreeClassifier Scores by min_samples_split')\n",
        "plt.plot(min_samples_split, train_scores, label='Train',linewidth=2, marker='o')\n",
        "plt.plot(min_samples_split, test_scores, label='Test',linewidth=2, marker='o')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "XhZzbnS7WeWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`min_samples_split`의 값을 크게 설정할 수록 학습용 데이터의 성능은 떨어지고 테스트용 데이터의 정확도는 약간 증가함을 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "DK2P2X5OWgYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1.3 min_samples_leaf"
      ],
      "metadata": {
        "id": "V3whj5i3Wij4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  변경할 min_samples_leaf \n",
        "min_samples_leaf=[1,2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "# 매개변수에 따른 학습데이터 셋, 테스트 데이터셋에 대한 정확도를 저장하기 위한 변수\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for i in min_samples_leaf:\n",
        "    # min_samples_leaf 변경하여 모델 생성\n",
        "    tuned_tree = DecisionTreeClassifier(random_state=42, _____________ = i)\n",
        "\n",
        "    # 생성한 tree 객체를 학습용 데이터를 사용하여 학습\n",
        "    tuned_tree.fit(X_train, y_train)\n",
        "\n",
        "    # 학습데이터 셋, 테스트 데이터셋에 대한 정확도를 저장\n",
        "    train_scores.append(tuned_tree.score(X_train, y_train))\n",
        "    test_scores.append(tuned_tree.score(X_test, y_test))\n",
        "    \n",
        "    # 정확도 출력\n",
        "    print(\"min_samples_leaf = {}, train 세트 정확도: {:.3f}, test 세트 정확도: {:.3f}\".\\\n",
        "          format(i, train_scores[i-1], test_scores[i-1]))"
      ],
      "metadata": {
        "id": "2tWhCt1KWmyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 매개변수 변화에 따른 학습데이터와 테스트데이터에 대한 정확도 변화 시각화\n",
        "plt.title('DecisionTreeClassifier Scores by min_samples_leaf')\n",
        "plt.plot(min_samples_leaf, train_scores, label='Train',linewidth=2, marker='o')\n",
        "plt.plot(min_samples_leaf, test_scores, label='Test',linewidth=2, marker='o')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "VOQRPW43Wojs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`min_samples_leaf`의 값을 크게 설정할 수록 학습용 데이터의 성능은 떨어지고 테스트용 데이터의 정확도는 약간 증가함을 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "2ftwpsZ2WqUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1.4 max_features"
      ],
      "metadata": {
        "id": "mvGzuOH2WsPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  변경할 max_features, 선언된 변수에서 10을 나눠주어 비율로 설정\n",
        "max_features=[1,2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "# 매개변수에 따른 학습데이터 셋, 테스트 데이터셋에 대한 정확도를 저장하기 위한 변수\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for i in max_features:\n",
        "    # max_features 변경하여 모델 생성\n",
        "    tuned_tree = DecisionTreeClassifier(random_state=42, ________________ = i/10)\n",
        "\n",
        "    # 생성한 tree 객체를 학습용 데이터를 사용하여 학습\n",
        "    tuned_tree.fit(X_train, y_train)\n",
        "\n",
        "    # 학습데이터 셋, 테스트 데이터셋에 대한 정확도를 저장\n",
        "    train_scores.append(tuned_tree.score(X_train, y_train))\n",
        "    test_scores.append(tuned_tree.score(X_test, y_test))\n",
        "    \n",
        "    # 정확도 출력\n",
        "    print(\"max_features = {}, train 세트 정확도: {:.3f}, test 세트 정확도: {:.3f}\".\\\n",
        "          format(i/10, train_scores[i-1], test_scores[i-1]))"
      ],
      "metadata": {
        "id": "-eF49cvZWvA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 매개변수 변화에 따른 학습데이터와 테스트데이터에 대한 정확도 변화 시각화\n",
        "plt.title('DecisionTreeClassifier Scores by max_features')\n",
        "plt.plot(max_features, train_scores, label='Train',linewidth=2, marker='o')\n",
        "plt.plot(max_features, test_scores, label='Test',linewidth=2, marker='o')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "trD9I91BWxF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`max_features`의 비율을 다르게 설정하더라도 모델의 성능 변화가 크게 없음을 확인할 수 있습니다. "
      ],
      "metadata": {
        "id": "yoV00WdPWzfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1.5 max_leaf_nodes"
      ],
      "metadata": {
        "id": "EuDc3WALW1Md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  변경할 max_leaf_nodes\n",
        "max_leaf_nodes=[2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "# 매개변수에 따른 학습데이터 셋, 테스트 데이터셋에 대한 정확도를 저장하기 위한 변수\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for i in max_leaf_nodes:\n",
        "    # max_features 변경하여 모델 생성\n",
        "    tuned_tree = DecisionTreeClassifier(random_state=42, ________________ = i)\n",
        "\n",
        "    # 생성한 tree 객체를 학습용 데이터를 사용하여 학습\n",
        "    tuned_tree.fit(X_train, y_train)\n",
        "\n",
        "    # 학습데이터 셋, 테스트 데이터셋에 대한 정확도를 저장\n",
        "    train_scores.append(tuned_tree.score(X_train, y_train))\n",
        "    test_scores.append(tuned_tree.score(X_test, y_test))\n",
        "    \n",
        "    # 정확도 출력\n",
        "    print(\"max_leaf_nodes = {}, train 세트 정확도: {:.3f}, test 세트 정확도: {:.3f}\".\\\n",
        "          format(i, train_scores[i-2], test_scores[i-2]))"
      ],
      "metadata": {
        "id": "DrPG7Gc6W376"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 매개변수 변화에 따른 학습데이터와 테스트데이터에 대한 정확도 변화 시각화\n",
        "plt.title('DecisionTreeClassifier Scores by max_leaf_nodes')\n",
        "plt.plot(max_leaf_nodes, train_scores, label='Train',linewidth=2, marker='o')\n",
        "plt.plot(max_leaf_nodes, test_scores, label='Test',linewidth=2, marker='o')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "UtdYjkrqW5ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`max_leaf_nodes`의 값을 크게 설정할 수록 학습용 데이터와 테스트용 데이터의 정확도가 모두 높아지고 있음을 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "g73ek2uHW65x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 SVC 매개변수 변경\n",
        "-----"
      ],
      "metadata": {
        "id": "5aXytbaqVA0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2.1 C\n",
        "-----"
      ],
      "metadata": {
        "id": "eCeJlFhNVLLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  변경할 C \n",
        "C=[1.0, 2.0, 3.0, 4.0, 5.0]\n",
        "\n",
        "# 매개변수에 따른 학습데이터 셋, 테스트 데이터셋에 대한 정확도를 저장하기 위한 변수\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for i in C:\n",
        "    # C를 변경하여 모델 생성\n",
        "    tuned_svc = SVC(____ = i)\n",
        "\n",
        "    # 생성한 SVC 객체를 학습용 데이터를 사용하여 학습\n",
        "    tuned_svc.fit(X_train, y_train)\n",
        "\n",
        "    # 학습데이터 셋, 테스트 데이터셋에 대한 정확도를 저장\n",
        "    train_scores.append(tuned_svc.score(X_train, y_train))\n",
        "    test_scores.append(tuned_svc.score(X_test, y_test))\n",
        "    \n",
        "    # 정확도 출력\n",
        "    print(\"C = {}, train 세트 정확도: {:.3f}, test 세트 정확도: {:.3f}\".\\\n",
        "          format(i, train_scores[int(i)-1], test_scores[int(i)-1]))"
      ],
      "metadata": {
        "id": "ZMqca_XFPjeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 매개변수 변화에 따른 학습데이터와 테스트데이터에 대한 정확도 변화 시각화\n",
        "plt.title('SVC Scores by C')\n",
        "plt.plot(C, train_scores, label='Train',linewidth=2, marker='o')\n",
        "plt.plot(C, test_scores, label='Test',linewidth=2, marker='o')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "GZeMn1Q5N0np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`C`를 2~4로 설정했을 때 테스트 셋의 정확도가 가장 높은 모델이 만들어졌습니다."
      ],
      "metadata": {
        "id": "sByxkXZKVVyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2.2 kernel\n",
        "-----"
      ],
      "metadata": {
        "id": "H-AvTaqmViq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  변경할 kernel\n",
        "kernel=['linear', 'poly', 'rbf', 'sigmoid']\n",
        "\n",
        "# 매개변수에 따른 학습데이터 셋, 테스트 데이터셋에 대한 정확도를 저장하기 위한 변수\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for i in kernel:\n",
        "    # kernel를 변경하여 모델 생성\n",
        "    tuned_svc = SVC(___________ = i)\n",
        "\n",
        "    # 생성한 SVC 객체를 학습용 데이터를 사용하여 학습\n",
        "    tuned_svc.fit(X_train, y_train)\n",
        "\n",
        "    # 학습데이터 셋, 테스트 데이터셋에 대한 정확도를 저장\n",
        "    train_scores.append(tuned_svc.score(X_train, y_train))\n",
        "    test_scores.append(tuned_svc.score(X_test, y_test))\n",
        "    \n",
        "    # 정확도 출력\n",
        "    print(\"C = {}, train 세트 정확도: {:.3f}, test 세트 정확도: {:.3f}\".\\\n",
        "          format(i, tuned_svc.score(X_train, y_train), tuned_svc.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "-QoEvfq9N0lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 매개변수 변화에 따른 학습데이터와 테스트데이터에 대한 정확도 변화 시각화\n",
        "plt.title('SVC Scores by kernel')\n",
        "index = np.arange(len(kernel))\n",
        "bar_width = 0.35\n",
        "plt.bar(index, train_scores, bar_width, label='Train')\n",
        "plt.bar(index + bar_width, test_scores, bar_width, label='Test')\n",
        "plt.xticks(index+ bar_width/2, kernel)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "FjmJfG-DN0bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`kernel`을 rbf로 설정하였을 때 가장 좋은 성능을 보이는 모델이 생성되었습니다."
      ],
      "metadata": {
        "id": "lCbg4nemVsuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 GridSearchCV - DecisionTree\n",
        "---\n",
        "cross_validate를 사용하여 기존의 학습데이터(X_train, y_train)를 3등분하여 학습데이터와 검증용 데이터의 역할을 번갈아 수행하는 교차검증을 진행합니다."
      ],
      "metadata": {
        "id": "zJHmyhDtaCUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cross_validate 라이브러리 불러오기\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# cross_validate를 사용하여 모델의 교차 검증\n",
        "scores = cross_validate(tree, X_train, y_train, cv=3, return_estimator=True)\n",
        "\n",
        "# cross_validate 결과 확인\n",
        "scores"
      ],
      "metadata": {
        "id": "6nl--WB2aSw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3개의 의사결정나무가 각각 다른 학습 데이터 셋을 사용하여 생성되었습니다. 3개의 의사결정나무를 테스트용 데이터셋을 사용하여 정확도를 확인합니다."
      ],
      "metadata": {
        "id": "MJxWAm0zaV1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3개의 분류기 평가\n",
        "for i in range(3):     \n",
        "    score = scores['estimator'][i].score(X_test, y_test)\n",
        "    print('{0}번째 의사결정나무 정확도: {1:.2f}'.format(i+1, score))"
      ],
      "metadata": {
        "id": "26FDXRkYaUsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3개의 의사결정나무의 평균 정확도는 교차검증을 수행하기 이전보다 감소하였습니다. GridSearchCV를 사용하여 교차검증을 수행하며 최적의 하이퍼파라미터를 찾습니다."
      ],
      "metadata": {
        "id": "gaSPJHy9aZAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 변경하여 설정할 매개변수의 항목을 딕셔너리 형태로 정의\n",
        "param = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}\n",
        "\n",
        "# GridSearchCV 객체 선언, 교차검증 3회 수행\n",
        "grid_trees = GridSearchCV(tree, param_grid=param, cv=3)\n",
        "\n",
        "# 학습 - param_grid의 하이퍼파라미터들을 순차적으로 학습\n",
        "grid_trees.fit(X_train, y_train)\n",
        "\n",
        "# 학습 결과 - GridSearchCV 결과 추출하여 DataFrame으로 변환\n",
        "scores_df = pd.DataFrame(grid_trees.cv_results_)\n",
        "\n",
        "# 학습결과를 담은 데이터프레임의 6번째 컬럼 이후부터 출력\n",
        "scores_df.iloc[:, 6:]"
      ],
      "metadata": {
        "id": "t8TXerDqagK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "변경하여 설정할 매개변수가 총 3 x 2 = 6개의 조합이 가능하므로, 6개의 의사결정나무에 대한 결과를 확인할 수 있습니다. rank_test_score가 가장 작은값인 {'max_depth': 3, 'min_samples_split': 2}와 {'max_depth': 3, 'min_samples_split': 3}의 성능이 약 80%로 가장 좋음을 확인할 수 있습니다. \n",
        "<br><br>\n",
        "GridSearchCV의 결과 중 최적의 성능을 보인 분류기에 대한 매개변수와 성능을 다음과 같이 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "s-D2_SnDae9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적 estimator\n",
        "grid_trees.best_estimator_"
      ],
      "metadata": {
        "id": "yw1McjBxar8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적 매개변수\n",
        "grid_trees.best_params_"
      ],
      "metadata": {
        "id": "kSHAGa1Oax7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적 estimator의 성능\n",
        "grid_trees.best_score_"
      ],
      "metadata": {
        "id": "tGIQEto6azRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "최적의 성능을 보인 의사결정나무를 사용하여 학습을 다시 수행합니다."
      ],
      "metadata": {
        "id": "rZk1e8pga1Vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성한 tree 객체를 학습용 데이터를 사용하여 학습\n",
        "grid_tree = grid_trees.best_estimator_ \n",
        "grid_trees.best_estimator_.fit(X_train, y_train)\n",
        "\n",
        "# 학습용 데이터 셋의 정확도\n",
        "print(\"train 세트 정확도: {:.3f}\".format(grid_tree.score(X_train, y_train)))\n",
        "\n",
        "# 테스트용 데이터 셋의 정확도\n",
        "print(\"test 세트 정확도: {:.3f}\".format(grid_tree.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "p0xAMM-Va062"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 GridSearchCV - SVM\n",
        "----\n",
        "GridSearchCV를 사용하여 교차검증을 수행하며 최적의 하이퍼파라미터를 찾습니다."
      ],
      "metadata": {
        "id": "wymoDgMRbY45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파라미터\n",
        "param = {'C':[1.0, 2.0, 3.0, 4.0, 5.0], 'kernel':['linear', 'poly', 'rbf', 'sigmoid']}\n",
        "\n",
        "# 학습 - param_grid의 하이퍼파라미터들을 순차적으로 학습\n",
        "grid_classifier = GridSearchCV(classifier, param_grid=param, cv=3)\n",
        "grid_classifier.fit(X_train, y_train)\n",
        "\n",
        "# 학습 결과 - GridSearchCV 결과 추출하여 DataFrame으로 변환\n",
        "scores_svm_df = pd.DataFrame(grid_classifier.cv_results_)\n",
        "\n",
        "# 학습결과를 담은 데이터프레임의 6번째 컬럼 이후부터 출력\n",
        "scores_svm_df.iloc[:, 6:]"
      ],
      "metadata": {
        "id": "aze9KK9tbsxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "최적의 성능을 보인 모델을 사용하여 학습을 다시 수행합니다."
      ],
      "metadata": {
        "id": "-ISAF2fkb2Tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성한 tree 객체를 학습용 데이터를 사용하여 학습\n",
        "svm_grid = grid_classifier.best_estimator_\n",
        "svm_grid.fit(X_train, y_train)\n",
        "\n",
        "# 학습용 데이터 셋의 정확도\n",
        "print(\"train 세트 정확도: {:.3f}\".format(svm_grid.score(X_train, y_train)))\n",
        "\n",
        "# 테스트용 데이터 셋의 정확도\n",
        "print(\"test 세트 정확도: {:.3f}\".format(svm_grid.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "nnRHpmIZb3YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "# [실습 02] breast cancer data\n",
        "-----\n",
        " \n",
        "위에서 학습한 내용을 유방암 데이터 셋을 사용하여 복습해봅니다."
      ],
      "metadata": {
        "id": "NUyTqSeAUXYf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeTQDHAzJ5Pb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "dataset = load_breast_cancer()\n",
        "df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
        "df['target'] = dataset.target\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pjwb0MIJMNHF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}